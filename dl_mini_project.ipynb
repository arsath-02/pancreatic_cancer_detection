{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYzDmdJ_j9Fp",
        "outputId": "9c8669f2-616b-49be-8724-c877f96446b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgyBRwJCkaMJ",
        "outputId": "77190cb3-7965-410b-8be5-8ba7ed40e40e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "mkdir ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI_2PUe2knuK",
        "outputId": "ced6851b-bd49-4864-a3f2-9c55be6221db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QXO33JDlDiN",
        "outputId": "37c6e930-a4e4-48c6-ac86-62c73c14c18c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ssw8v7zoihr",
        "outputId": "56d0d379-2e2a-4df4-e4d0-a1ad758f93b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.15 / client 1.6.14)\n",
            "Dataset URL: https://www.kaggle.com/datasets/jayaprakashpondy/pancreatic-ct-images\n",
            "License(s): CC0-1.0\n",
            "pancreatic-ct-images.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d jayaprakashpondy/pancreatic-ct-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X_ei5Oaoqwi"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'dataset.zip' with the name of your zip file\n",
        "with zipfile.ZipFile('pancreatic-ct-images.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('dataset')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWa6bNZ4qAnv"
      },
      "outputs": [],
      "source": [
        "train ='/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRnApHFHVl3o",
        "outputId": "c16e0c47-3890-4b4c-ff26-02956f912d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 1 classes.\n",
            "Found 199 images belonging to 1 classes.\n",
            "Epoch 1/20\n",
            "25/25 [==============================] - 20s 659ms/step - loss: 0.0334 - accuracy: 0.9750 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 10s 422ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 11s 458ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 11s 438ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 13s 511ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 10s 406ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 11s 436ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 10s 407ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 11s 456ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 13s 514ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 13s 512ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 10s 412ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 10s 395ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 10s 413ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 10s 409ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 11s 438ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 11s 434ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 10s 406ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 9s 375ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 10s 393ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABSm0lEQVR4nO3de1xUdf4/8NcZLjOA3BEGlNsaiVdIEcT8pa5smK6G6YqkacZqbUIiXbzkvS20VmNNV9b9ltauhLGrrFFhSGYXUVS0sq/a5avgbUBCQAa5zZzfH8TocJPLwJkZXs/HYx46Zz7nnPfB2Hnt5/M5nyOIoiiCiIiIiHRkUhdAREREZGwYkIiIiIiaYEAiIiIiaoIBiYiIiKgJBiQiIiKiJhiQiIiIiJpgQCIiIiJqggGJiIiIqAkGJCIiIqImGJCIqFcQBAHr1q3r8H6XLl2CIAjYvXt3m+0+//xzCIKAzz//vFP1EZFxYUAioh6ze/duCIIAQRDw1VdfNftcFEV4e3tDEAT8/ve/l6BCIqIGDEhE1OMUCgVSU1ObbT9y5AiuXLkCuVwuQVVERHcwIBFRj5s8eTLS09NRX1+vtz01NRUjR46EUqmUqDIiogYMSETU42JiYvDLL78gOztbt622thb//ve/8fjjj7e4j1qtxvPPPw9vb2/I5XIMHDgQf/nLXyCKol67mpoaLF26FH379oW9vT2mTZuGK1eutHjMq1ev4qmnnoKHhwfkcjmGDBmCd955x3AXCiA9PR0jR46EjY0N3NzcMHfuXFy9elWvjUqlwoIFC9C/f3/I5XJ4enri0UcfxaVLl3RtTp48icjISLi5ucHGxgb+/v546qmnDForEd1hKXUBRNT7+Pn5ITw8HO+//z4eeeQRAMAnn3yC8vJyzJ49G1u3btVrL4oipk2bhsOHDyM2NhbBwcE4ePAgXnzxRVy9ehVvvvmmru0f//hH/Otf/8Ljjz+OMWPG4LPPPsOUKVOa1VBUVITRo0dDEATExcWhb9+++OSTTxAbG4uKigokJCR0+Tp3796NBQsWYNSoUUhKSkJRURH++te/4uuvv8bp06fh5OQEAJgxYwa+//57xMfHw8/PD8XFxcjOzkZhYaHu/cMPP4y+ffti+fLlcHJywqVLl7Bv374u10hErRCJiHrIrl27RADiiRMnxG3bton29vZiVVWVKIqi+Ic//EGcMGGCKIqi6OvrK06ZMkW3X0ZGhghA/POf/6x3vJkzZ4qCIIg//fSTKIqieObMGRGA+Oyzz+q1e/zxx0UA4tq1a3XbYmNjRU9PT7GkpESv7ezZs0VHR0ddXRcvXhQBiLt27Wrz2g4fPiwCEA8fPiyKoijW1taK7u7u4tChQ8Xbt2/r2mVmZooAxDVr1oiiKIo3b94UAYhvvPFGq8fev3+/7udGRD2DQ2xEJIlZs2bh9u3byMzMxK1bt5CZmdnq8NrHH38MCwsLPPfcc3rbn3/+eYiiiE8++UTXDkCzdk17g0RRxH/+8x9MnToVoiiipKRE94qMjER5eTny8/O7dH0nT55EcXExnn32WSgUCt32KVOmIDAwEB999BEAwMbGBtbW1vj8889x8+bNFo/V2NOUmZmJurq6LtVFRO3DgEREkujbty8iIiKQmpqKffv2QaPRYObMmS22LSgogJeXF+zt7fW2Dxo0SPd5458ymQwDBgzQazdw4EC99zdu3EBZWRl27tyJvn376r0WLFgAACguLu7S9TXW1PTcABAYGKj7XC6XY9OmTfjkk0/g4eGBhx56CK+//jpUKpWu/bhx4zBjxgysX78ebm5uePTRR7Fr1y7U1NR0qUYiah3nIBGRZB5//HEsXLgQKpUKjzzyiK6npLtptVoAwNy5czF//vwW2wwfPrxHagEaerimTp2KjIwMHDx4EKtXr0ZSUhI+++wzPPDAAxAEAf/+979x7NgxfPjhhzh48CCeeuopbN68GceOHUOfPn16rFai3oI9SEQkmenTp0Mmk+HYsWOtDq8BgK+vL65du4Zbt27pbT9//rzu88Y/tVotfv75Z712Fy5c0HvfeIebRqNBREREiy93d/cuXVtjTU3P3bit8fNGAwYMwPPPP49PP/0UZ8+eRW1tLTZv3qzXZvTo0Xj11Vdx8uRJ7NmzB99//z3S0tK6VCcRtYwBiYgk06dPH+zYsQPr1q3D1KlTW203efJkaDQabNu2TW/7m2++CUEQdHfCNf7Z9C645ORkvfcWFhaYMWMG/vOf/+Ds2bPNznfjxo3OXI6ekJAQuLu7IyUlRW8o7JNPPsG5c+d0d9ZVVVWhurpab98BAwbA3t5et9/NmzebLWcQHBwMABxmI+omHGIjIkm1NsR1t6lTp2LChAl4+eWXcenSJQQFBeHTTz/Ff//7XyQkJOjmHAUHByMmJgZ/+9vfUF5ejjFjxiAnJwc//fRTs2Nu3LgRhw8fRlhYGBYuXIjBgwejtLQU+fn5OHToEEpLS7t0XVZWVti0aRMWLFiAcePGISYmRnebv5+fH5YuXQoA+OGHHzBx4kTMmjULgwcPhqWlJfbv34+ioiLMnj0bAPDuu+/ib3/7G6ZPn44BAwbg1q1b+Mc//gEHBwdMnjy5S3USUcsYkIjI6MlkMhw4cABr1qzB3r17sWvXLvj5+eGNN97A888/r9f2nXfeQd++fbFnzx5kZGTgt7/9LT766CN4e3vrtfPw8EBeXh42bNiAffv24W9/+xtcXV0xZMgQbNq0ySB1P/nkk7C1tcXGjRuxbNky2NnZYfr06di0aZNuvpW3tzdiYmKQk5ODf/7zn7C0tERgYCA++OADzJgxA0DDJO28vDykpaWhqKgIjo6OCA0NxZ49e+Dv72+QWolInyA27bclIiIi6uU4B4mIiIioCQYkIiIioiYYkIiIiIiaMIqAtH37dvj5+UGhUCAsLAx5eXlttk9PT0dgYCAUCgWGDRume7xAo3Xr1iEwMBB2dnZwdnZGREQEjh8/rtfGz88PgiDovTZu3GjwayMiIiLTI3lA2rt3LxITE7F27Vrk5+cjKCgIkZGRrS7zf/ToUcTExCA2NhanT59GVFQUoqKi9NYyuf/++7Ft2zZ89913+Oqrr+Dn54eHH3642domGzZswPXr13Wv+Pj4br1WIiIiMg2S38UWFhaGUaNG6RaA02q18Pb2Rnx8PJYvX96sfXR0NNRqNTIzM3XbRo8ejeDgYKSkpLR4joqKCjg6OuLQoUOYOHEigIYepISEhGYPsSQiIiKSdB2k2tpanDp1CitWrNBtk8lkiIiIQG5ubov75ObmIjExUW9bZGQkMjIyWj3Hzp074ejoiKCgIL3PNm7ciFdeeQU+Pj54/PHHsXTpUlhatvwjqamp0VuxVqvVorS0FK6urhAEoT2XS0RERBITRRG3bt2Cl5cXZLLWB9IkDUglJSXQaDTw8PDQ2+7h4aF7xlJTKpWqxfZ3P/kaADIzMzF79mxUVVXB09MT2dnZcHNz033+3HPPYcSIEXBxccHRo0exYsUKXL9+HVu2bGnxvElJSVi/fn1nLpOIiIiMzOXLl9G/f/9WPzfblbQnTJiAM2fOoKSkBP/4xz8wa9YsHD9+XPcAyrt7oYYPHw5ra2s8/fTTSEpKglwub3a8FStW6O1TXl4OHx8fXL58GQ4ODt1/QURERNRlFRUV8Pb2hr29fZvtJA1Ibm5usLCwQFFRkd72oqIiKJXKFvdRKpXtam9nZ4f77rsP9913H0aPHo2AgAC8/fbbesN5dwsLC0N9fT0uXbqEgQMHNvtcLpe3GJwcHBwYkIiIiEzMvabHSHoXm7W1NUaOHImcnBzdNq1Wi5ycHISHh7e4T3h4uF57AMjOzm61/d3Hbeup12fOnIFMJtP1MBEREVHvJfkQW2JiIubPn4+QkBCEhoYiOTkZarUaCxYsAADMmzcP/fr1Q1JSEgBgyZIlGDduHDZv3owpU6YgLS0NJ0+exM6dOwEAarUar776KqZNmwZPT0+UlJRg+/btuHr1Kv7whz8AaJjoffz4cUyYMAH29vbIzc3F0qVLMXfuXDg7O0vzgyAiIiKjIXlAio6Oxo0bN7BmzRqoVCoEBwcjKytLNxG7sLBQb5b5mDFjkJqailWrVmHlypUICAhARkYGhg4dCgCwsLDA+fPn8e6776KkpASurq4YNWoUvvzySwwZMgRAw3BZWloa1q1bh5qaGvj7+2Pp0qXN7o4jIiKi3knydZBMVePaSuXl5W3OQdJoNKirq+vByqi7WFlZwcLCQuoyiIioC9r7/S15D5K5EkURKpUKZWVlUpdCBuTk5ASlUsm1r4iIzBwDUjdpDEfu7u6wtbXlF6qJE0URVVVVukfgeHp6SlwRERF1JwakbqDRaHThyNXVVepyyEBsbGwAAMXFxXB3d+dwGxGRGZP8YbXmqHHOka2trcSVkKE1/ptyXhkRkXljQOpGHFYzP/w3JSLqHRiQiIiIiJpgQKJu5efnh+TkZKnLICIi6hAGJALQMHTU1mvdunWdOu6JEyewaNEiwxZLRETUzXgXm5HRakXUarSwshBgIeu5/Hr9+nXd3/fu3Ys1a9bgwoULum19+vTR/V0URWg0Glha3vs/n759+xq2UCIioh7AHiQj838lavxQdAuVNZoePa9SqdS9HB0dIQiC7v358+dhb2+PTz75BCNHjoRcLsdXX32Fn3/+GY8++ig8PDzQp08fjBo1CocOHdI7btMhNkEQ8D//8z+YPn06bG1tERAQgAMHDvTotRIREd0LA1IPEEURVbX17XppNCKq6zQor6pt9z5tvQz5JJnly5dj48aNOHfuHIYPH47KykpMnjwZOTk5OH36NCZNmoSpU6eisLCwzeOsX78es2bNwrfffovJkydjzpw5KC0tNVidREREXcUhth5wu06DwWsOSnLu/90QCVtrw/wzb9iwAb/73e90711cXBAUFKR7/8orr2D//v04cOAA4uLiWj3Ok08+iZiYGADAa6+9hq1btyIvLw+TJk0ySJ1ERERdxR4kareQkBC995WVlXjhhRcwaNAgODk5oU+fPjh37tw9e5CGDx+u+7udnR0cHBx0j/AgIiIyBuxB6gE2Vhb43w2R7WpbWV2PS7+oIbeUIcDD3iDnNhQ7Ozu99y+88AKys7Pxl7/8Bffddx9sbGwwc+ZM1NbWtnkcKysrvfeCIECr1RqsTiIioq5iQOoBgiC0e5jLUiaDoqIaAgTYWFkY9crNX3/9NZ588klMnz4dQEOP0qVLl6QtioiIyAA4xGZkrCwa1h0SIaJOY9y9KgEBAdi3bx/OnDmDb775Bo8//jh7goiIyCwwIBkZQRBgbdHwz1Jbb9xhY8uWLXB2dsaYMWMwdepUREZGYsSIEVKXRURE1GWCaMj7wHuRiooKODo6ory8HA4ODnqfVVdX4+LFi/D394dCoejwsS+WqHGrug79nW3gYic3VMlkAF39tyUiImm19f19N/YgGSFry4Z/lhoj70EiIiIyVwxIRshUhtiIiIjMFQOSEWrsQao18knaRERE5ooByQjpAhJ7kIiIiCTBgGSEGofYNFoR9exFIiIi6nEMSEbIQibAUtbwT2PsayERERGZIwYkI8U72YiIiKTDgGSkOFGbiIhIOgxIRooTtYmIiKTDgGSkTHEtpPHjxyMhIUH33s/PD8nJyW3uIwgCMjIyunxuQx2HiIgIYEAyWvIeHmKbOnUqJk2a1OJnX375JQRBwLffftuhY544cQKLFi0yRHk669atQ3BwcLPt169fxyOPPGLQcxERUe/FgGSkGofY6upFaHvgcXmxsbHIzs7GlStXmn22a9cuhISEYPjw4R06Zt++fWFra2uoEtukVCohl/O5dUREZBgMSEbKUiZAJggQIfbIrf6///3v0bdvX+zevVtve2VlJdLT0xEVFYWYmBj069cPtra2GDZsGN5///02j9l0iO3HH3/EQw89BIVCgcGDByM7O7vZPsuWLcP9998PW1tb/OY3v8Hq1atRV1cHANi9ezfWr1+Pb775BoIgQBAEXb1Nh9i+++47/Pa3v4WNjQ1cXV2xaNEiVFZW6j5/8sknERUVhb/85S/w9PSEq6srFi9erDsXERH1bpZSF9AriCJQV9WhXQQA1tpq1NRrUFsFyBVWnTu3lS0gCPdsZmlpiXnz5mH37t14+eWXIfy6T3p6OjQaDebOnYv09HQsW7YMDg4O+Oijj/DEE09gwIABCA0NvefxtVotHnvsMXh4eOD48eMoLy/Xm6/UyN7eHrt374aXlxe+++47LFy4EPb29njppZcQHR2Ns2fPIisrC4cOHQIAODo6NjuGWq1GZGQkwsPDceLECRQXF+OPf/wj4uLi9ALg4cOH4enpicOHD+Onn35CdHQ0goODsXDhwnteDxERmTcGpJ5QVwW85tXh3e43xLlXXgOs7drV9KmnnsIbb7yBI0eOYPz48QAahtdmzJgBX19fvPDCC7q28fHxOHjwID744IN2BaRDhw7h/PnzOHjwILy8Gn4Wr732WrN5Q6tWrdL93c/PDy+88ALS0tLw0ksvwcbGBn369IGlpSWUSmWr50pNTUV1dTXee+892Nk1XPu2bdswdepUbNq0CR4eHgAAZ2dnbNu2DRYWFggMDMSUKVOQk5PDgERERBxiozsCAwMxZswYvPPOOwCAn376CV9++SViY2Oh0WjwyiuvYNiwYXBxcUGfPn1w8OBBFBYWtuvY586dg7e3ty4cAUB4eHizdnv37sWDDz4IpVKJPn36YNWqVe0+x93nCgoK0oUjAHjwwQeh1Wpx4cIF3bYhQ4bAwsJC997T0xPFxcUdOhcREZkn9iD1BCvbhp6cDiqprMH18mo42ljBx6WTk52tOrZfbGws4uPjsX37duzatQsDBgzAuHHjsGnTJvz1r39FcnIyhg0bBjs7OyQkJKC2trZzdbUgNzcXc+bMwfr16xEZGQlHR0ekpaVh8+bNBjvH3ays9IctBUGAVms6yyoQEVH3YUDqCYLQ7mGuu1nbWEOskqFGsOjU/p0xa9YsLFmyBKmpqXjvvffwpz/9CYIg4Ouvv8ajjz6KuXPnAmiYU/TDDz9g8ODB7TruoEGDcPnyZVy/fh2enp4AgGPHjum1OXr0KHx9ffHyyy/rthUUFOi1sba2hkajuee5du/eDbVaretF+vrrryGTyTBw4MB21UtERL0bh9iM2N2raYs9cKs/APTp0wfR0dFYsWIFrl+/jieffBIAEBAQgOzsbBw9ehTnzp3D008/jaKionYfNyIiAvfffz/mz5+Pb775Bl9++aVeEGo8R2FhIdLS0vDzzz9j69at2L9/v14bPz8/XLx4EWfOnEFJSQlqamqanWvOnDlQKBSYP38+zp49i8OHDyM+Ph5PPPGEbv4RERFRWxiQjFjjatoaUYRG2zMBCWgYZrt58yYiIyN1c4ZWrVqFESNGIDIyEuPHj4dSqURUVFS7jymTybB//37cvn0boaGh+OMf/4hXX31Vr820adOwdOlSxMXFITg4GEePHsXq1av12syYMQOTJk3ChAkT0Ldv3xaXGrC1tcXBgwdRWlqKUaNGYebMmZg4cSK2bdvW8R8GERH1SoLYU10TZqaiogKOjo4oLy+Hg4OD3mfV1dW4ePEi/P39oVAounSec9crUKfR4j73PrC15oio1Az5b0tERD2vre/vu7EHyciZ4jPZiIiITJ1RBKTt27fDz88PCoUCYWFhyMvLa7N9eno6AgMDoVAoMGzYMHz88cd6n69btw6BgYGws7ODs7MzIiIicPz4cb02paWlmDNnDhwcHODk5ITY2Fi9lZaNxd3zkIiIiKhnSB6Q9u7di8TERKxduxb5+fkICgpCZGRkq+vRHD16FDExMYiNjcXp06cRFRWFqKgonD17Vtfm/vvvx7Zt2/Ddd9/hq6++gp+fHx5++GHcuHFD12bOnDn4/vvvkZ2djczMTHzxxRcGf7CqITAgERER9TzJ5yCFhYVh1KhRugm0Wq0W3t7eiI+Px/Lly5u1j46OhlqtRmZmpm7b6NGjERwcjJSUlBbP0TjeeOjQIUycOBHnzp3D4MGDceLECYSEhAAAsrKyMHnyZFy5ckVvMcPW9NQcpJtVtbhcWgU7uSUG9O3TpWNR13EOEhGRaTOJOUi1tbU4deoUIiIidNtkMhkiIiKQm5vb4j65ubl67QEgMjKy1fa1tbXYuXMnHB0dERQUpDuGk5OTLhwBDbehy2SyZkNxjWpqalBRUaH3uhdDZM/GOUh17EEyCryngYiod5A0IJWUlECj0TRbm8bDwwMqlarFfVQqVbvaZ2Zmok+fPlAoFHjzzTeRnZ0NNzc33THc3d312ltaWsLFxaXV8yYlJcHR0VH38vb2bvW6Gldorqrq2ANqW6IbYtNooeWXs+Qa/02brsJNRETmxWzvG58wYYJuMcF//OMfmDVrFo4fP94sGLXXihUrkJiYqHtfUVHRakiysLCAk5OTbh6Vra0tBEHo1HlFUQQ0dRBFEZWVVbC2srj3TmRwoiiiqqoKxcXFcHJy0nuGGxERmR9JA5KbmxssLCyarchcVFTU6tPalUplu9rb2dnhvvvuw3333YfRo0cjICAAb7/9NlasWAGlUtlsEnh9fT1KS0tbPa9cLodcLm/3tTUexxAPPy2tqEadRoS2whoKBiRJOTk5tfrfCBERmQ9JA5K1tTVGjhyJnJwc3arMWq0WOTk5iIuLa3Gf8PBw5OTkICEhQbctOzu7xSfD302r1eoeSxEeHo6ysjKcOnUKI0eOBAB89tln0Gq1CAsL6/qFoeHBp56ennB3d0ddXV2XjvVOxlkc/bkE8b8NQNQD/QxSH3WclZUVe46IiHoJyYfYEhMTMX/+fISEhCA0NBTJyclQq9VYsGABAGDevHno168fkpKSAABLlizBuHHjsHnzZkyZMgVpaWk4efIkdu7cCQBQq9V49dVXMW3aNHh6eqKkpATbt2/H1atX8Yc//AFAw8NMJ02ahIULFyIlJQV1dXWIi4vD7Nmz23UHW0dYWFh0+UvVoY8trt7S4KdfanjnFBERUQ+QPCBFR0fjxo0bWLNmDVQqFYKDg5GVlaWbiF1YWAiZ7M5c8jFjxiA1NRWrVq3CypUrERAQgIyMDAwdOhRAQyA5f/483n33XZSUlMDV1RWjRo3Cl19+iSFDhuiOs2fPHsTFxWHixImQyWSYMWMGtm7d2rMX306+rrYAgILSrk/6JiIionuTfB0kU9XedRQM4fCFYizYdQKBSntkJTzUreciIiIyZyaxDhK1j49LQw9SYWkV1+EhIiLqAQxIJqC/sw0EAaiq1aCkslbqcoiIiMweA5IJkFtawNOhYXJ2IechERERdTsGJBPh8+tE7csMSERERN2OAclENM5DKviFAYmIiKi7MSCZiLsnahMREVH3YkAyET6udgA4xEZERNQTGJBMhG6IrVQtcSVERETmjwHJRDQGpKKKGlTXaSSuhoiIyLwxIJkIZ1sr2Msbngxz5SaH2YiIiLoTA5KJEAQB3ryTjYiIqEcwIJkQ3slGRETUMxiQTIivKwMSERFRT2BAMiGNQ2yFHGIjIiLqVgxIJoRDbERERD2DAcmE3D3EptWKEldDRERkvhiQTIiXkw0sZAJq6rW4UVkjdTlERERmiwHJhFhZyODlpADAYTYiIqLuxIBkYny4FhIREVG3Y0AyMZyoTURE1P0YkEyMj4sdAOAyAxIREVG3YUAyMXeG2NQSV0JERGS+GJBMzJ0httsSV0JERGS+GJBMjM+vayGVVNagqrZe4mqIiIjMEwOSiXG0sYKjjRUATtQmIiLqLgxIJsiHz2QjIiLqVgxIJsjHlbf6ExERdScGJBPEtZCIiIi6FwOSCWJAIiIi6l4MSCbIlwGJiIioWzEgmSDvXwPSldLb0GhFiashIiIyPwxIJsjLyQaWMgG1Gi2KKqqlLoeIiMjsMCCZIAuZgP7ONgCAAt7qT0REZHAMSCaqcZiND60lIiIyPAYkE+XLtZCIiIi6DQOSiWq81b+AAYmIiMjgGJBMFNdCIiIi6j4MSCbKx8UOAOcgERERdQcGJBPl7dJwF1upuha3quskroaIiMi8GEVA2r59O/z8/KBQKBAWFoa8vLw226enpyMwMBAKhQLDhg3Dxx9/rPusrq4Oy5Ytw7Bhw2BnZwcvLy/MmzcP165d0zuGn58fBEHQe23cuLFbrq872Cus4GJnDYDDbERERIYmeUDau3cvEhMTsXbtWuTn5yMoKAiRkZEoLi5usf3Ro0cRExOD2NhYnD59GlFRUYiKisLZs2cBAFVVVcjPz8fq1auRn5+Pffv24cKFC5g2bVqzY23YsAHXr1/XveLj47v1Wg3Nh7f6ExERdQtBFEVJn1URFhaGUaNGYdu2bQAArVYLb29vxMfHY/ny5c3aR0dHQ61WIzMzU7dt9OjRCA4ORkpKSovnOHHiBEJDQ1FQUAAfHx8ADT1ICQkJSEhI6FTdFRUVcHR0RHl5ORwcHDp1jK567v3TOPDNNax4JBBPjxsgSQ1ERESmpL3f35L2INXW1uLUqVOIiIjQbZPJZIiIiEBubm6L++Tm5uq1B4DIyMhW2wNAeXk5BEGAk5OT3vaNGzfC1dUVDzzwAN544w3U19e3eoyamhpUVFTovaTGO9mIiIi6h6WUJy8pKYFGo4GHh4fedg8PD5w/f77FfVQqVYvtVSpVi+2rq6uxbNkyxMTE6CXF5557DiNGjICLiwuOHj2KFStW4Pr169iyZUuLx0lKSsL69es7cnndzoeLRRIREXULSQNSd6urq8OsWbMgiiJ27Nih91liYqLu78OHD4e1tTWefvppJCUlQS6XNzvWihUr9PapqKiAt7d39xXfDuxBIiIi6h6SBiQ3NzdYWFigqKhIb3tRURGUSmWL+yiVyna1bwxHBQUF+Oyzz+45TygsLAz19fW4dOkSBg4c2OxzuVzeYnCSUmNAunrzNuo1WlhaSD7nnoiIyCxI+o1qbW2NkSNHIicnR7dNq9UiJycH4eHhLe4THh6u1x4AsrOz9do3hqMff/wRhw4dgqur6z1rOXPmDGQyGdzd3Tt5NT1P6aCAtYUM9VoR18urpS6HiIjIbEg+xJaYmIj58+cjJCQEoaGhSE5OhlqtxoIFCwAA8+bNQ79+/ZCUlAQAWLJkCcaNG4fNmzdjypQpSEtLw8mTJ7Fz504ADeFo5syZyM/PR2ZmJjQajW5+kouLC6ytrZGbm4vjx49jwoQJsLe3R25uLpYuXYq5c+fC2dlZmh9EJ8hkAvq72OD/bqhRWFoF7197lIiIiKhrJA9I0dHRuHHjBtasWQOVSoXg4GBkZWXpJmIXFhZCJrvT0TVmzBikpqZi1apVWLlyJQICApCRkYGhQ4cCAK5evYoDBw4AAIKDg/XOdfjwYYwfPx5yuRxpaWlYt24dampq4O/vj6VLl+rNMTIVvi62uoD0oNTFEBERmQnJ10EyVcawDhIArP3vWbybW4Bnxg3A8kcCJauDiIjIFJjEOkjUdd5cTZuIiMjgGJBMnK+rHQDe6k9ERGRIDEgmrvFW/4Jf1BJXQkREZD4YkEyct4sNAKCiuh7lVXUSV0NERGQeGJBMnK21JfraNyxgyWE2IiIiw2BAMgO6YbZSDrMREREZAgOSGeAz2YiIiAyLAckM+PBWfyIiIoNiQDIDd+5kY0AiIiIyBAYkM+DjyiE2IiIiQ2JAMgO+v/YgXSu7jTqNVuJqiIiITB8Dkhnoay+HwkoGrQhcvXlb6nKIiIhMHgOSGRAEgXeyERERGRADkplgQCIiIjIcBiQz4c2AREREZDAMSGaicaJ2IW/1JyIi6jIGJDPReKt/AXuQiIiIuowByUzcvZq2KIoSV0NERGTaGJDMRH/nhoBUWVOPm1V1EldDRERk2hiQzITCygJKBwUAoOAXtcTVEBERmTYGJDPCW/2JiIgMgwHJjDRO1L7MgERERNQlDEhmpLEHqYC3+hMREXUJA5IZ4RAbERGRYTAgmREOsRERERkGA5IZaexBul5RjZp6jcTVEBERmS4GJDPiamcNO2sLiCJw5eZtqcshIiIyWQxIZkQQBD60loiIyAAYkMyMDx9aS0RE1GUMSGbG15U9SERERF3FgGRmeKs/ERFR1zEgmRlvDrERERF1GQOSmfF1tQPQ0IMkiqLE1RAREZkmBiQz08/JBoIA3K7T4EZljdTlEBERmSQGJDNjbSmDl6MNAK6oTURE1FkMSGaIE7WJiIi6hgHJDDUGpAJO1CYiIuoUBiQz5MO1kIiIiLqEAckMNfYgcQ4SERFR5xhFQNq+fTv8/PygUCgQFhaGvLy8Ntunp6cjMDAQCoUCw4YNw8cff6z7rK6uDsuWLcOwYcNgZ2cHLy8vzJs3D9euXdM7RmlpKebMmQMHBwc4OTkhNjYWlZWV3XJ9PY1DbERERF0jeUDau3cvEhMTsXbtWuTn5yMoKAiRkZEoLi5usf3Ro0cRExOD2NhYnD59GlFRUYiKisLZs2cBAFVVVcjPz8fq1auRn5+Pffv24cKFC5g2bZrecebMmYPvv/8e2dnZyMzMxBdffIFFixZ1+/X2hMaAVHyrBrdrNRJXQ0REZHoEUeLVBMPCwjBq1Chs27YNAKDVauHt7Y34+HgsX768Wfvo6Gio1WpkZmbqto0ePRrBwcFISUlp8RwnTpxAaGgoCgoK4OPjg3PnzmHw4ME4ceIEQkJCAABZWVmYPHkyrly5Ai8vr3vWXVFRAUdHR5SXl8PBwaEzl95tRFHE8PWf4lZ1PbKXPoQAD3upSyIiIjIK7f3+lrQHqba2FqdOnUJERIRum0wmQ0REBHJzc1vcJzc3V689AERGRrbaHgDKy8shCAKcnJx0x3ByctKFIwCIiIiATCbD8ePHu3BFxkEQBA6zERERdYGkAamkpAQajQYeHh562z08PKBSqVrcR6VSdah9dXU1li1bhpiYGF1SVKlUcHd312tnaWkJFxeXVo9TU1ODiooKvZcx8+WdbERERJ0m+Ryk7lRXV4dZs2ZBFEXs2LGjS8dKSkqCo6Oj7uXt7W2gKruHNxeLJCIi6jRJA5KbmxssLCxQVFSkt72oqAhKpbLFfZRKZbvaN4ajgoICZGdn640zKpXKZpPA6+vrUVpa2up5V6xYgfLyct3r8uXL7b5OKXA1bSIios6TNCBZW1tj5MiRyMnJ0W3TarXIyclBeHh4i/uEh4frtQeA7OxsvfaN4ejHH3/EoUOH4Orq2uwYZWVlOHXqlG7bZ599Bq1Wi7CwsBbPK5fL4eDgoPcyZr4udgAYkIiIiDrDUuoCEhMTMX/+fISEhCA0NBTJyclQq9VYsGABAGDevHno168fkpKSAABLlizBuHHjsHnzZkyZMgVpaWk4efIkdu7cCaAhHM2cORP5+fnIzMyERqPRzStycXGBtbU1Bg0ahEmTJmHhwoVISUlBXV0d4uLiMHv27HbdwWYK7l4sUqsVIZMJEldERERkOiQPSNHR0bhx4wbWrFkDlUqF4OBgZGVl6SZiFxYWQia709E1ZswYpKamYtWqVVi5ciUCAgKQkZGBoUOHAgCuXr2KAwcOAACCg4P1znX48GGMHz8eALBnzx7ExcVh4sSJkMlkmDFjBrZu3dr9F9xDPJ0UsJAJqKnXovhWDZSOCqlLIiIiMhmSr4Nkqox5HaRGD71+GIWlVfjg6XCE+rtIXQ4REZHkTGIdJOped9ZCUktcCRERkWlhQDJj3nxoLRERUacwIJkxLhZJRETUOQxIZkw3xMaARERE1CEMSGbMh0NsREREncKAZMZ8fh1iK6mshbqmXuJqiIiITAcDkhlzUFjBydYKAOchERERdQQDkpnz5TPZiIiIOowByczxVn8iIqKOY0Ayc3cWi2RAIiIiai8GJDPHtZCIiIg6jgHJzHGIjYiIqOMYkMycbi2km1XQaPlcYiIiovZgQDJzno42sLIQUKcRoaqolrocIiIik8CAZOYsZAL6O/86D4kTtYmIiNqlUwHp8uXLuHLliu59Xl4eEhISsHPnToMVRobjrVsLSS1xJURERKahUwHp8ccfx+HDhwEAKpUKv/vd75CXl4eXX34ZGzZsMGiB1HVcLJKIiKhjOhWQzp49i9DQUADABx98gKFDh+Lo0aPYs2cPdu/ebcj6yAC4FhIREVHHdCog1dXVQS6XAwAOHTqEadOmAQACAwNx/fp1w1VHBsFb/YmIiDqmUwFpyJAhSElJwZdffons7GxMmjQJAHDt2jW4uroatEDqOi4WSURE1DGdCkibNm3C3//+d4wfPx4xMTEICgoCABw4cEA39EbGo7EH6WZVHSqq6ySuhoiIyPhZdman8ePHo6SkBBUVFXB2dtZtX7RoEWxtbQ1WHBlGH7kl3PpYo6SyFoW/VGFoP0epSyIiIjJqnepBun37NmpqanThqKCgAMnJybhw4QLc3d0NWiAZBuchERERtV+nAtKjjz6K9957DwBQVlaGsLAwbN68GVFRUdixY4dBCyTD0N3JxoBERER0T50KSPn5+fh//+//AQD+/e9/w8PDAwUFBXjvvfewdetWgxZIhsG1kIiIiNqvUwGpqqoK9vb2AIBPP/0Ujz32GGQyGUaPHo2CggKDFkiGwSE2IiKi9utUQLrvvvuQkZGBy5cv4+DBg3j44YcBAMXFxXBwcDBogWQYXCySiIio/ToVkNasWYMXXngBfn5+CA0NRXh4OICG3qQHHnjAoAWSYfi62gEArpbdRr1GK3E1RERExq1Tt/nPnDkTY8eOxfXr13VrIAHAxIkTMX36dIMVR4bjbi+HtaUMtfVaXC+v1g25ERERUXOdCkgAoFQqoVQqceXKFQBA//79uUikEZPJBHg72+DnG2oU/FLFgERERNSGTg2xabVabNiwAY6OjvD19YWvry+cnJzwyiuvQKvl8I2xahxm451sREREbetUD9LLL7+Mt99+Gxs3bsSDDz4IAPjqq6+wbt06VFdX49VXXzVokWQYPrzVn4iIqF06FZDeffdd/M///A+mTZum2zZ8+HD069cPzz77LAOSkfLWBSS1xJUQEREZt04NsZWWliIwMLDZ9sDAQJSWlna5KOoeXCySiIiofToVkIKCgrBt27Zm27dt24bhw4d3uSjqHj6ud9ZCEkVR4mqIiIiMV6eG2F5//XVMmTIFhw4d0q2BlJubi8uXL+Pjjz82aIFkON7ODQHpVnU9ym/XwcnWWuKKiIiIjFOnepDGjRuHH374AdOnT0dZWRnKysrw2GOP4fvvv8c///lPQ9dIBmJjbQF3ezkADrMRERG1RRANONbyzTffYMSIEdBoNIY6pNGqqKiAo6MjysvLTerxKjN3HMXJgpt4K+YBTA3ykrocIiKiHtXe7+9O9SCR6Wqch8QeJCIiotYxIPUyjWshXWZAIiIiapXkAWn79u3w8/ODQqFAWFgY8vLy2myfnp6OwMBAKBQKDBs2rNmk8H379uHhhx+Gq6srBEHAmTNnmh1j/PjxEARB7/XMM88Y8rKMVmNAKviFAYmIiKg1HbqL7bHHHmvz87Kysg6dfO/evUhMTERKSgrCwsKQnJyMyMhIXLhwAe7u7s3aHz16FDExMUhKSsLvf/97pKamIioqCvn5+Rg6dCgAQK1WY+zYsZg1axYWLlzY6rkXLlyIDRs26N7b2vaOZ5P5coiNiIjonjo0SXvBggXtardr1652tQsLC8OoUaN0aypptVp4e3sjPj4ey5cvb9Y+OjoaarUamZmZum2jR49GcHAwUlJS9NpeunQJ/v7+OH36NIKDg/U+Gz9+PIKDg5GcnNyuOltiqpO0i29VI/TVHMgE4Pwrj8DaUvJORCIioh7T3u/vDvUgtTf4tEdtbS1OnTqFFStW6LbJZDJEREQgNze3xX1yc3ORmJioty0yMhIZGRkdPv+ePXvwr3/9C0qlElOnTsXq1avb7EWqqalBTU2N7n1FRUWHz2kM+vaRw8bKArfrNLhadhv+bnZSl0RERGR0OrVQpCGUlJRAo9HAw8NDb7uHhwfOnz/f4j4qlarF9iqVqkPnfvzxx+Hr6wsvLy98++23WLZsGS5cuIB9+/a1uk9SUhLWr1/fofMYI0EQ4ONiiwtFt1BYWsWARERE1ALJApKUFi1apPv7sGHD4OnpiYkTJ+Lnn3/GgAEDWtxnxYoVer1XFRUV8Pb27vZau4P3XQGJiIiImpMsILm5ucHCwgJFRUV624uKiqBUKlvcR6lUdqh9e4WFhQEAfvrpp1YDklwuh1wu79J5jEXjnWyFv6glroSIiMg4STZD19raGiNHjkROTo5um1arRU5Oju75bk2Fh4frtQeA7OzsVtu3V+NSAJ6enl06jqngnWxERERtk3SILTExEfPnz0dISAhCQ0ORnJwMtVqtu1tu3rx56NevH5KSkgAAS5Yswbhx47B582ZMmTIFaWlpOHnyJHbu3Kk7ZmlpKQoLC3Ht2jUAwIULFwA09D4plUr8/PPPSE1NxeTJk+Hq6opvv/0WS5cuxUMPPYThw4f38E9AGroepNLbEldCRERknCQNSNHR0bhx4wbWrFkDlUqF4OBgZGVl6SZiFxYWQia708k1ZswYpKamYtWqVVi5ciUCAgKQkZGhWwMJAA4cOKC3HMHs2bMBAGvXrsW6detgbW2NQ4cO6cKYt7c3ZsyYgVWrVvXQVUvP+64hNlEUIQiCxBUREREZF4M+rLY3MdV1kACguk6DQWuyIIrAqVURcO1jHnOriIiI7oUPq6VWKawsoHRQAAAKOA+JiIioGQakXooPrSUiImodA1IvdedWfwYkIiKiphiQeqnGgMQhNiIiouYYkHopH66FRERE1CoGpF6Kc5CIiIhax4DUSzUGJFVFNarrNBJXQ0REZFwYkHopFztr9JFbQhSBKze5ojYREdHdGJB6KUEQdCtqc5iNiIhIHwNSL+bjYgMAKPhFLXElRERExoUBqRfzdbUDwIfWEhERNcWA1IvpHlrLITYiIiI9DEi9mG417VIOsREREd2NAakX872rB0kURYmrISIiMh4MSL2Yl5MNZAJQXafFjcoaqcshIiIyGgxIvZi1pQyejg13svGhtURERHcwIPVyvnwmGxERUTMMSL1c40TtAvYgERER6TAg9XI+rlxNm4iIqCkGpF7Oh2shERERNcOA1MvphtgYkIiIiHQYkHo5X5eGx43cuFWD27UaiashIiIyDgxIvZyjrRUcFJYAgMs32YtEREQEMCAR7kzU5p1sREREDRiQSDfMxonaREREDRiQCN4uvNWfiIjobgxIdNdikWqJKyEiIjIODEjEx40QERE1wYBEuh6kyzdvQ6sVJa6GiIhIegxIBE9HBSxlAmrrtSi6VS11OURERJJjQCJYWsjQz9kGAFDIW/2JiIgYkKgBn8lGRER0BwMSAWBAIiIiuhsDEgFgQCIiIrobAxIBuHstJAYkIiIiBiQCcOd5bFxNm4iIiAGJftX4uJFf1LWorKmXuBoiIiJpMSARAMBBYQVnWysAvNWfiIiIAYl0fFztAHCiNhERkeQBafv27fDz84NCoUBYWBjy8vLabJ+eno7AwEAoFAoMGzYMH3/8sd7n+/btw8MPPwxXV1cIgoAzZ840O0Z1dTUWL14MV1dX9OnTBzNmzEBRUZEhL8sk6R45woBERES9nKQBae/evUhMTMTatWuRn5+PoKAgREZGori4uMX2R48eRUxMDGJjY3H69GlERUUhKioKZ8+e1bVRq9UYO3YsNm3a1Op5ly5dig8//BDp6ek4cuQIrl27hscee8zg12dqfFwaVtMuKFVLXAkREZG0BFEUJXs6aVhYGEaNGoVt27YBALRaLby9vREfH4/ly5c3ax8dHQ21Wo3MzEzdttGjRyM4OBgpKSl6bS9dugR/f3+cPn0awcHBuu3l5eXo27cvUlNTMXPmTADA+fPnMWjQIOTm5mL06NHtqr2iogKOjo4oLy+Hg4NDRy/dKH1w4jJe+s+3eOj+vnjvqVCpyyEiIjK49n5/S9aDVFtbi1OnTiEiIuJOMTIZIiIikJub2+I+ubm5eu0BIDIystX2LTl16hTq6ur0jhMYGAgfH582j1NTU4OKigq9l7nx5hAbERERAAkDUklJCTQaDTw8PPS2e3h4QKVStbiPSqXqUPvWjmFtbQ0nJ6cOHScpKQmOjo66l7e3d7vPaSoa10K6crMKGq1kHYtERESSk3yStqlYsWIFysvLda/Lly9LXZLBKR0UsLaQoU4j4nr5banLISIikoxkAcnNzQ0WFhbN7h4rKiqCUqlscR+lUtmh9q0do7a2FmVlZR06jlwuh4ODg97L3FjIBPR3bpiozVv9iYioN5MsIFlbW2PkyJHIycnRbdNqtcjJyUF4eHiL+4SHh+u1B4Ds7OxW27dk5MiRsLKy0jvOhQsXUFhY2KHjmKvGYTYuFklERL2ZpZQnT0xMxPz58xESEoLQ0FAkJydDrVZjwYIFAIB58+ahX79+SEpKAgAsWbIE48aNw+bNmzFlyhSkpaXh5MmT2Llzp+6YpaWlKCwsxLVr1wA0hB+goedIqVTC0dERsbGxSExMhIuLCxwcHBAfH4/w8PB238FmzhrXQmIPEhER9WaSBqTo6GjcuHEDa9asgUqlQnBwMLKysnQTsQsLCyGT3enkGjNmDFJTU7Fq1SqsXLkSAQEByMjIwNChQ3VtDhw4oAtYADB79mwAwNq1a7Fu3ToAwJtvvgmZTIYZM2agpqYGkZGR+Nvf/tYDV2z8GJCIiIgkXgfJlJnjOkgA8On3Kiz65ykM7++IA3FjpS6HiIjIoIx+HSQyTro5SOxBIiKiXowBifR4OzcEpLKqOpTfrpO4GiIiImkwIJEeO7kl3PrIAXBFbSIi6r0YkKiZxofWcpiNiIh6KwYkaqbxTrYCroVERES9FAMSNePjageAPUhERNR7MSBRM409SJyDREREvRUDEjWjG2IrVUtcCRERkTQYkKgZ31/XQrpWVo06jVbiaoiIiHoeAxI107ePHHJLGTRaEdfLqqUuh4iIqMcxIFEzMpkAbw6zERFRL8aARC3y5UNriYioF2NAohZ5MyAREVEvxoBELWqcqF3IxSKJiKgXYkCiFvmwB4mIiHoxBiRqkS4g/VIFURQlroaIiKhnMSBRixrnIN2qqUdZVZ3E1RAREfUsBiRqkcLKAh4OcgAcZiMiot6HAYladeeRIwxIRETUuzAgUat8XOwA8KG1RETU+zAgUavunqhNRETUmzAgUat8XG0A8HEjRETU+zAgUavuDLHdlrgSIiKinsWARK1qHGK7Vn4btfVaiashIiLqOQxI1Cq3PtawtbaAKAJXbnIeEhER9R4MSNQqQRD4yBEiIuqVGJCoTY0ravNWfyIi6k0YkKhNvo2LRfJWfyIi6kUYkKhNPq4cYiMiot6HAYna5M05SERE1AsxIFGbfO8KSKIoSlwNERFRz2BAojb1c7aBIABVtRr8oq6VuhwiIqIewYBEbZJbWsDTQQGAw2xERNR7MCDRPekmavNONiIi6iUYkOieuFgkERH1NgxIdE8+XAuJiIh6GQYkuicfVzsAXE2biIh6DwYkuicOsRERUW/DgET31BiQVBXVqK7TSFwNERFR9zOKgLR9+3b4+flBoVAgLCwMeXl5bbZPT09HYGAgFAoFhg0bho8//ljvc1EUsWbNGnh6esLGxgYRERH48ccf9dr4+flBEAS918aNGw1+bebA2dYK9nJLAMCVm+xFIiIi8yd5QNq7dy8SExOxdu1a5OfnIygoCJGRkSguLm6x/dGjRxETE4PY2FicPn0aUVFRiIqKwtmzZ3VtXn/9dWzduhUpKSk4fvw47OzsEBkZierqar1jbdiwAdevX9e94uPju/VaTZUgCHzkCBER9SqSB6QtW7Zg4cKFWLBgAQYPHoyUlBTY2trinXfeabH9X//6V0yaNAkvvvgiBg0ahFdeeQUjRozAtm3bADT0HiUnJ2PVqlV49NFHMXz4cLz33nu4du0aMjIy9I5lb28PpVKpe9nZ2XX35ZosX1feyUZERL2HpAGptrYWp06dQkREhG6bTCZDREQEcnNzW9wnNzdXrz0AREZG6tpfvHgRKpVKr42joyPCwsKaHXPjxo1wdXXFAw88gDfeeAP19fWGujSzw4naRETUm1hKefKSkhJoNBp4eHjobffw8MD58+db3EelUrXYXqVS6T5v3NZaGwB47rnnMGLECLi4uODo0aNYsWIFrl+/ji1btrR43pqaGtTU1OjeV1RUtPMqzUPjEBtv9Sciot5A0oAkpcTERN3fhw8fDmtrazz99NNISkqCXC5v1j4pKQnr16/vyRKNCofYiIioN5F0iM3NzQ0WFhYoKirS215UVASlUtniPkqlss32jX925JgAEBYWhvr6ely6dKnFz1esWIHy8nLd6/Lly21em7m5e4hNFEWJqyEiIupekgYka2trjBw5Ejk5ObptWq0WOTk5CA8Pb3Gf8PBwvfYAkJ2drWvv7+8PpVKp16aiogLHjx9v9ZgAcObMGchkMri7u7f4uVwuh4ODg96rN/FysoGFTEBNvRY3btXcewciIiITJvkQW2JiIubPn4+QkBCEhoYiOTkZarUaCxYsAADMmzcP/fr1Q1JSEgBgyZIlGDduHDZv3owpU6YgLS0NJ0+exM6dOwE03JKekJCAP//5zwgICIC/vz9Wr14NLy8vREVFAWiY6H38+HFMmDAB9vb2yM3NxdKlSzF37lw4OztL8nMwdlYWMng5KXC59DYKSqvg7qCQuiQiIqJuI3lAio6Oxo0bN7BmzRqoVCoEBwcjKytLN8m6sLAQMtmdjq4xY8YgNTUVq1atwsqVKxEQEICMjAwMHTpU1+all16CWq3GokWLUFZWhrFjxyIrKwsKRcOXulwuR1paGtatW4eamhr4+/tj6dKlevOSqDkfF1tcLr2Nwl+qMMrPRepyiIiIuo0gckJJp1RUVMDR0RHl5eW9Zrhtxb5v8X7eZSyZGIClv7tf6nKIiIg6rL3f35IvFEmmw8elYSFNroVERETmjgGJ2o2LRRIRUW/BgETt1hiQuBYSERGZOwYkajefXxeLLKmsQVUtH8tCRETmiwGJ2s3RxgqONlYAgMultyWuhoiIqPswIFGH3BlmU0tcCRERUfdhQKIOaRxm40RtIiIyZwxI1CGNPUiXGZCIiMiMMSBRh/g2DrExIBERkRljQKIO4VpIRETUGzAgUYd4/xqQrpTehlbLp9QQEZF5YkCiDvFysoGlTECtRgtVRbXU5RAREXULBiTqEAuZgP7ONgA4zEZEROaLAYk6zJvzkIiIyMwxIFGH+TauhcRnshERkZliQKIO451sRERk7hiQqMMYkIiIyNwxIFGH+bjYAWBAIiIi88WARB3m7dJwF1upuha3quskroaIiMjwGJCow+wVVnCxswbAXiQiIjJPDEjUKXxoLRERmTMGJOoUTtQmIiJzxoBEndK4FlIB10IiIiIzxIBEncLVtImIyJwxIFGncA4SERGZMwYk6pTGIbYrN2+jXqOVuBoiIiLDYkCiTvGwV8DaQoZ6rYjr5dVSl0NERGRQDEjUKTKZgP6/LhjJYTYiIjI3DEjUab6/zkMqYEAiIiIzw4BEnca1kIiIyFwxIFGn8VZ/IiIyVwxI1Gm+rnYAgEIuFklERGaGAYk6jUNsRERkrhiQqNO8f72Lrfx2Hcqr6iSuhoiIyHAYkKjTbK0t0ddeDoC9SEREZF4YkKhLOMxGRETmiAGJuuTOWkhqiSshIiIyHAYk6hJvPrSWiIjMEAMSdQmH2IiIyBwxIFGX+Lr+OsTGtZCIiMiMGEVA2r59O/z8/KBQKBAWFoa8vLw226enpyMwMBAKhQLDhg3Dxx9/rPe5KIpYs2YNPD09YWNjg4iICPz44496bUpLSzFnzhw4ODjAyckJsbGxqKysNPi1mbvGHqRrZbdRp9FKXA0REZFhSB6Q9u7di8TERKxduxb5+fkICgpCZGQkiouLW2x/9OhRxMTEIDY2FqdPn0ZUVBSioqJw9uxZXZvXX38dW7duRUpKCo4fPw47OztERkaiurpa12bOnDn4/vvvkZ2djczMTHzxxRdYtGhRt1+vuelrL4fCSgat2BCSiIiIzIEgiqIoZQFhYWEYNWoUtm3bBgDQarXw9vZGfHw8li9f3qx9dHQ01Go1MjMzddtGjx6N4OBgpKSkQBRFeHl54fnnn8cLL7wAACgvL4eHhwd2796N2bNn49y5cxg8eDBOnDiBkJAQAEBWVhYmT56MK1euwMvL6551V1RUwNHREeXl5XBwcDDEjwIQRaDO9Iaqpm37Cj8WV+L1GcMxwtdZ6nKIiMhMuDo5QWFtadBjtvf727Bn7aDa2lqcOnUKK1as0G2TyWSIiIhAbm5ui/vk5uYiMTFRb1tkZCQyMjIAABcvXoRKpUJERITuc0dHR4SFhSE3NxezZ89Gbm4unJycdOEIACIiIiCTyXD8+HFMnz692XlrampQU1Oje19RUdGpa25TXRXw2r3DmbE5AAAKAB9JXAgREZmVr2Z9i7GDfSU5t6RDbCUlJdBoNPDw8NDb7uHhAZVK1eI+KpWqzfaNf96rjbu7u97nlpaWcHFxafW8SUlJcHR01L28vb3beZVERETUGTJBkOzckvYgmZIVK1bo9VxVVFQYPiRZ2QIrrxn2mERERCZqjJWtZOeWNCC5ubnBwsICRUVFetuLioqgVCpb3EepVLbZvvHPoqIieHp66rUJDg7WtWk6Cby+vh6lpaWtnlcul0Mul7f/4jpDEABru+49BxEREd2TpENs1tbWGDlyJHJycnTbtFotcnJyEB4e3uI+4eHheu0BIDs7W9fe398fSqVSr01FRQWOHz+uaxMeHo6ysjKcOnVK1+azzz6DVqtFWFiYwa6PiIiITJPkQ2yJiYmYP38+QkJCEBoaiuTkZKjVaixYsAAAMG/ePPTr1w9JSUkAgCVLlmDcuHHYvHkzpkyZgrS0NJw8eRI7d+4EAAiCgISEBPz5z39GQEAA/P39sXr1anh5eSEqKgoAMGjQIEyaNAkLFy5ESkoK6urqEBcXh9mzZ7frDjYiIiIyb5IHpOjoaNy4cQNr1qyBSqVCcHAwsrKydJOsCwsLIZPd6egaM2YMUlNTsWrVKqxcuRIBAQHIyMjA0KFDdW1eeuklqNVqLFq0CGVlZRg7diyysrKgUCh0bfbs2YO4uDhMnDgRMpkMM2bMwNatW3vuwomIiMhoSb4OkqnqlnWQiIiIqFu19/tb8pW0iYiIiIwNAxIRERFREwxIRERERE0wIBERERE1wYBERERE1AQDEhEREVETDEhERERETTAgERERETXBgERERETUhOSPGjFVjQuQV1RUSFwJERERtVfj9/a9HiTCgNRJt27dAgB4e3tLXAkRERF11K1bt+Do6Njq53wWWydptVpcu3YN9vb2EATBYMetqKiAt7c3Ll++bDLPeDPFmgHTrJs19wzW3DNYc89gzfpEUcStW7fg5eUFmaz1mUbsQeokmUyG/v37d9vxHRwcTOY/5EamWDNgmnWz5p7BmnsGa+4ZrPmOtnqOGnGSNhEREVETDEhERERETTAgGRm5XI61a9dCLpdLXUq7mWLNgGnWzZp7BmvuGay5Z7DmzuEkbSIiIqIm2INERERE1AQDEhEREVETDEhERERETTAgERERETXBgGRktm/fDj8/PygUCoSFhSEvL0/qklqVlJSEUaNGwd7eHu7u7oiKisKFCxekLqtDNm7cCEEQkJCQIHUpbbp69Srmzp0LV1dX2NjYYNiwYTh58qTUZbVKo9Fg9erV8Pf3h42NDQYMGIBXXnnlns8+6mlffPEFpk6dCi8vLwiCgIyMDL3PRVHEmjVr4OnpCRsbG0RERODHH3+UpthftVVzXV0dli1bhmHDhsHOzg5eXl6YN28erl27Jl3BuPfP+W7PPPMMBEFAcnJyj9XXkvbUfO7cOUybNg2Ojo6ws7PDqFGjUFhY2PPF/upeNVdWViIuLg79+/eHjY0NBg8ejJSUFGmKRfu+Q6qrq7F48WK4urqiT58+mDFjBoqKinqkPgYkI7J3714kJiZi7dq1yM/PR1BQECIjI1FcXCx1aS06cuQIFi9ejGPHjiE7Oxt1dXV4+OGHoVarpS6tXU6cOIG///3vGD58uNSltOnmzZt48MEHYWVlhU8++QT/+7//i82bN8PZ2Vnq0lq1adMm7NixA9u2bcO5c+ewadMmvP7663jrrbekLk2PWq1GUFAQtm/f3uLnr7/+OrZu3YqUlBQcP34cdnZ2iIyMRHV1dQ9XekdbNVdVVSE/Px+rV69Gfn4+9u3bhwsXLmDatGkSVHrHvX7Ojfbv349jx47By8urhypr3b1q/vnnnzF27FgEBgbi888/x7fffovVq1dDoVD0cKV33KvmxMREZGVl4V//+hfOnTuHhIQExMXF4cCBAz1caYP2fIcsXboUH374IdLT03HkyBFcu3YNjz32WM8UKJLRCA0NFRcvXqx7r9FoRC8vLzEpKUnCqtqvuLhYBCAeOXJE6lLu6datW2JAQICYnZ0tjhs3TlyyZInUJbVq2bJl4tixY6Uuo0OmTJkiPvXUU3rbHnvsMXHOnDkSVXRvAMT9+/fr3mu1WlGpVIpvvPGGbltZWZkol8vF999/X4IKm2tac0vy8vJEAGJBQUHPFHUPrdV85coVsV+/fuLZs2dFX19f8c033+zx2lrTUs3R0dHi3LlzpSmoHVqqeciQIeKGDRv0to0YMUJ8+eWXe7Cy1jX9DikrKxOtrKzE9PR0XZtz586JAMTc3Nxur4c9SEaitrYWp06dQkREhG6bTCZDREQEcnNzJays/crLywEALi4uEldyb4sXL8aUKVP0ft7G6sCBAwgJCcEf/vAHuLu744EHHsA//vEPqctq05gxY5CTk4MffvgBAPDNN9/gq6++wiOPPCJxZe138eJFqFQqvf9GHB0dERYWZjK/k0DD76UgCHBycpK6lFZptVo88cQTePHFFzFkyBCpy7knrVaLjz76CPfffz8iIyPh7u6OsLCwNocOjcGYMWNw4MABXL16FaIo4vDhw/jhhx/w8MMPS10agObfIadOnUJdXZ3e72BgYCB8fHx65HeQAclIlJSUQKPRwMPDQ2+7h4cHVCqVRFW1n1arRUJCAh588EEMHTpU6nLalJaWhvz8fCQlJUldSrv83//9H3bs2IGAgAAcPHgQf/rTn/Dcc8/h3Xfflbq0Vi1fvhyzZ89GYGAgrKys8MADDyAhIQFz5syRurR2a/y9M9XfSaBh/sayZcsQExNj1A8p3bRpEywtLfHcc89JXUq7FBcXo7KyEhs3bsSkSZPw6aefYvr06Xjsscdw5MgRqctr1VtvvYXBgwejf//+sLa2xqRJk7B9+3Y89NBDUpfW4neISqWCtbV1s3DfU7+Dlt1+BuoVFi9ejLNnz+Krr76SupQ2Xb58GUuWLEF2drakcwU6QqvVIiQkBK+99hoA4IEHHsDZs2eRkpKC+fPnS1xdyz744APs2bMHqampGDJkCM6cOYOEhAR4eXkZbc3mpq6uDrNmzYIoitixY4fU5bTq1KlT+Otf/4r8/HwIgiB1Oe2i1WoBAI8++iiWLl0KAAgODsbRo0eRkpKCcePGSVleq9566y0cO3YMBw4cgK+vL7744gssXrwYXl5ekvemG+N3CHuQjISbmxssLCyazc4vKiqCUqmUqKr2iYuLQ2ZmJg4fPoz+/ftLXU6bTp06heLiYowYMQKWlpawtLTEkSNHsHXrVlhaWkKj0UhdYjOenp4YPHiw3rZBgwZJerfMvbz44ou6XqRhw4bhiSeewNKlS02m1w6A7vfOFH8nG8NRQUEBsrOzjbr36Msvv0RxcTF8fHx0v5MFBQV4/vnn4efnJ3V5LXJzc4OlpaVJ/V7evn0bK1euxJYtWzB16lQMHz4ccXFxiI6Oxl/+8hdJa2vtO0SpVKK2thZlZWV67Xvqd5AByUhYW1tj5MiRyMnJ0W3TarXIyclBeHi4hJW1ThRFxMXFYf/+/fjss8/g7+8vdUn3NHHiRHz33Xc4c+aM7hUSEoI5c+bgzJkzsLCwkLrEZh588MFmt77+8MMP8PX1laiie6uqqoJMpv8/LxYWFrr/520K/P39oVQq9X4nKyoqcPz4caP9nQTuhKMff/wRhw4dgqurq9QltemJJ57At99+q/c76eXlhRdffBEHDx6UurwWWVtbY9SoUSb1e1lXV4e6ujqj+r2813fIyJEjYWVlpfc7eOHCBRQWFvbI7yCH2IxIYmIi5s+fj5CQEISGhiI5ORlqtRoLFiyQurQWLV68GKmpqfjvf/8Le3t73Ziwo6MjbGxsJK6uZfb29s3mSNnZ2cHV1dVo504tXboUY8aMwWuvvYZZs2YhLy8PO3fuxM6dO6UurVVTp07Fq6++Ch8fHwwZMgSnT5/Gli1b8NRTT0ldmp7Kykr89NNPuvcXL17EmTNn4OLiAh8fHyQkJODPf/4zAgIC4O/vj9WrV8PLywtRUVFGWbOnpydmzpyJ/Px8ZGZmQqPR6H4vXVxcYG1tbXQ1+/j4NAtxVlZWUCqVGDhwYE+XqnOvml988UVER0fjoYcewoQJE5CVlYUPP/wQn3/+udHWPG7cOLz44ouwsbGBr68vjhw5gvfeew9btmyRpN57fYc4OjoiNjYWiYmJcHFxgYODA+Lj4xEeHo7Ro0d3f4Hdfp8cdchbb70l+vj4iNbW1mJoaKh47NgxqUtqFYAWX7t27ZK6tA4x9tv8RVEUP/zwQ3Ho0KGiXC4XAwMDxZ07d0pdUpsqKirEJUuWiD4+PqJCoRB/85vfiC+//LJYU1MjdWl6Dh8+3OJ/w/PnzxdFseFW/9WrV4seHh6iXC4XJ06cKF64cMFoa7548WKrv5eHDx82yppbYgy3+ben5rffflu87777RIVCIQYFBYkZGRnSFSzeu+br16+LTz75pOjl5SUqFApx4MCB4ubNm0WtVitJve35Drl9+7b47LPPis7OzqKtra04ffp08fr16z1Sn/BrkURERET0K85BIiIiImqCAYmIiIioCQYkIiIioiYYkIiIiIiaYEAiIiIiaoIBiYiIiKgJBiQiIiKiJhiQiIgMRBAEZGRkSF0GERkAAxIRmYUnn3wSgiA0e02aNEnq0ojIBPFZbERkNiZNmoRdu3bpbZPL5RJVQ0SmjD1IRGQ25HI5lEql3svZ2RlAw/DXjh078Mgjj8DGxga/+c1v8O9//1tv/++++w6//e1vYWNjA1dXVyxatAiVlZV6bd555x0MGTIEcrkcnp6eiIuL0/u8pKQE06dPh62tLQICAnDgwIHuvWgi6hYMSETUa6xevRozZszAN998gzlz5mD27Nk4d+4cAECtViMyMhLOzs44ceIE0tPTcejQIb0AtGPHDixevBiLFi3Cd999hwMHDuC+++7TO8f69esxa9YsfPvtt5g8eTLmzJmD0tLSHr1OIjKAHnkkLhFRN5s/f75oYWEh2tnZ6b1effVVURQbnhz+zDPP6O0TFhYm/ulPfxJFURR37twpOjs7i5WVlbrPP/roI1Emk4kqlUoURVH08vISX3755VZrACCuWrVK976yslIEIH7yyScGu04i6hmcg0REZmPChAnYsWOH3jYXFxfd38PDw/U+Cw8Px5kzZwAA586dQ1BQEOzs7HSfP/jgg9Bqtbhw4QIEQcC1a9cwceLENmsYPny47u92dnZwcHBAcXFxZy+JiCTCgEREZsPOzq7ZkJeh2NjYtKudlZWV3ntBEKDVarujJCLqRpyDRES9xrFjx5q9HzRoEABg0KBB+Oabb6BWq3Wff/3115DJZBg4cCDs7e3h5+eHnJycHq2ZiKTBHiQiMhs1NTVQqVR62ywtLeHm5gYASE9PR0hICMaOHYs9e/YgLy8Pb7/9NgBgzpw5WLt2LebPn49169bhxo0biI+PxxNPPAEPDw8AwLp16/DMM8/A3d0djzzyCG7duoWvv/4a8fHxPXuhRNTtGJCIyGxkZWXB09NTb9vAgQNx/vx5AA13mKWlpeHZZ5+Fp6cn3n//fQwePBgAYGtri4MHD2LJkiUYNWoUbG1tMWPGDGzZskV3rPnz56O6uhpvvvkmXnjhBbi5uWHmzJk9d4FE1GMEURRFqYsgIupugiBg//79iIqKkroUIjIBnINERERE1AQDEhEREVETnINERL0CZxMQUUewB4mIiIioCQYkIiIioiYYkIiIiIiaYEAiIiIiaoIBiYiIiKgJBiQiIiKiJhiQiIiIiJpgQCIiIiJqggGJiIiIqIn/D6+W6+cHa5q2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001 # Fixed learning rate\n",
        "\n",
        "train_dir = '/content/dataset/DATASET/train'\n",
        "test_dir = '/content/dataset/DATASET/test'\n",
        "\n",
        "#Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "rescale=1./255,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "rotation_range=40,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "brightness_range=[0.8, 1.2],\n",
        "horizontal_flip=True,\n",
        "validation_split=0.2\n",
        ")\n",
        "\n",
        "#Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "train_dir,\n",
        "target_size=IMAGE_SIZE,\n",
        "batch_size=BATCH_SIZE,\n",
        "class_mode='binary',\n",
        "subset='training' # specify subset as 'training'\n",
        ")\n",
        "\n",
        "#Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "train_dir,\n",
        "target_size=IMAGE_SIZE,\n",
        "batch_size=BATCH_SIZE,\n",
        "class_mode='binary',\n",
        "subset='validation' # specify subset as 'validation'\n",
        ")\n",
        "\n",
        "#CNN model implementation\n",
        "model = Sequential([\n",
        "Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Conv2D(64, (3, 3), activation='relu'),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Conv2D(128, (3, 3), activation='relu'),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Conv2D(128, (3, 3), activation='relu'),\n",
        "MaxPooling2D(pool_size=(2, 2)),\n",
        "Flatten(),\n",
        "Dense(512, activation='relu'),\n",
        "Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "#Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "history = model.fit(\n",
        "train_generator,\n",
        "steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "epochs=20,\n",
        "validation_data=validation_generator,\n",
        "validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Assuming 'history' is a variable that contains the training history of your model\n",
        "#Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11]) # Adjusting the slicing to match the range\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11]) # Adjusting the slicing to match the range\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11]) # Adjusting the slicing to match the range\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11]) # Adjusting the slicing to match the range\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h1c4MlRzXXVV",
        "outputId": "8ecc8d78-0ac5-4b4a-c834-e2ca9b987edf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_datagen' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-118933b83240>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_generator = test_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_datagen' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "test_dir,\n",
        "target_size=IMAGE_SIZE,\n",
        "batch_size=BATCH_SIZE,\n",
        "class_mode='binary',\n",
        "shuffle=False\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "biZXnFHa0iI0"
      },
      "outputs": [],
      "source": [
        "# CNN WIHOUT AUGUMENATION\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "\n",
        "train ='/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "\n",
        "# Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# CNN model implementation\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure that 'history' contains enough data for the given range\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 20, 2), history.history['loss'][:10])  # Only take first 10 elements\n",
        "plt.plot(range(0, 20, 2), history.history['val_loss'][:10])  # Only take first 10 elements\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 20, 2))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 20, 2), history.history['accuracy'][:10])  # Only take first 10 elements\n",
        "plt.plot(range(0, 20, 2), history.history['val_accuracy'][:10])  # Only take first 10 elements\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 20, 2))\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PRW3Pv-Wyx"
      },
      "source": [
        "**MLP WITH *AUGMENTATION* **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eo-_2ZLQ18iU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train ='/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# MLP model implementation\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),  # Flatten the input\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M9xHVDK209bL"
      },
      "outputs": [],
      "source": [
        "#MLP WITHOUT AUGMENTATION\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train ='/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# MLP model implementation\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),  # Flatten the input\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4heLui4b80OF"
      },
      "outputs": [],
      "source": [
        "#resnet50 with augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # ResNet-50's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top (fully connected) layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # ResNet50 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OjIDiKz616tX"
      },
      "outputs": [],
      "source": [
        "#resnet50 without augumentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # ResNet-50's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing and augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained ResNet50 model without the top (fully connected) layers\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # ResNet50 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NtlpExd84Umm"
      },
      "outputs": [],
      "source": [
        "#inception v3 with augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (299, 299)  # InceptionV3's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained InceptionV3 model without the top (fully connected) layers\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # InceptionV3 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ujeR-aq34Mdu"
      },
      "outputs": [],
      "source": [
        "#inception v3 without augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (299, 299)  # InceptionV3's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained InceptionV3 model without the top (fully connected) layers\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # InceptionV3 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "51ZShAa19bv9"
      },
      "outputs": [],
      "source": [
        "#desnet121 with augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # DenseNet121's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing with augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained DenseNet121 model without the top layers\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # DenseNet121 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Data preprocessing without augmentation for test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "# Load test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_AnP9EUI43Fg"
      },
      "outputs": [],
      "source": [
        "#desnet121 without augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # DenseNet121's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained DenseNet121 model without the top (fully connected) layers\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # DenseNet121 base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Gg3odSE-pK2"
      },
      "outputs": [],
      "source": [
        "#mobilenet with augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # MobileNet's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained MobileNet model without the top (fully connected) layers\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # MobileNet base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wtUBDmm66JRN"
      },
      "outputs": [],
      "source": [
        "#mobile50 without augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # MobileNet's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained MobileNet model without the top (fully connected) layers\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # MobileNet base model\n",
        "    GlobalAveragePooling2D(),  # Global average pooling to reduce spatial dimensions\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TcOXLVSj6-qS"
      },
      "outputs": [],
      "source": [
        "#vgg19 with augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.applications import VGG19\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # VGG19's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG19 model without the top (fully connected) layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # VGG19 base model\n",
        "    Flatten(),  # Flatten the output of the base model\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dyPyB7c27pYw"
      },
      "outputs": [],
      "source": [
        "#vgg19 without augmentation\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.applications import VGG19\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define constants\n",
        "IMAGE_SIZE = (224, 224)  # VGG19's default input size\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001  # Fixed learning rate\n",
        "\n",
        "train = '/content/dataset/DATASET/train/train'\n",
        "test = '/content/dataset/DATASET/test/test'\n",
        "\n",
        "# Data preprocessing without augmentation for training and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train,  # Path to the training data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load validation data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Load the pre-trained VGG19 model without the top (fully connected) layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create a new model on top of the base model\n",
        "model = Sequential([\n",
        "    base_model,  # VGG19 base model\n",
        "    Flatten(),  # Flatten the output of the base model\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model with fixed learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is a variable that contains the training history of your model\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(range(0, 21, 2), history.history['loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_loss'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(range(0, 21, 2), history.history['accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.plot(range(0, 21, 2), history.history['val_accuracy'][:11])  # Adjusting to match the range 0-20 with steps of 2\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.xticks(range(0, 21, 2))  # Including the 0 and stepping by 2\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Load test data\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test,  # Path to the test data\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',  # Assuming it's a binary classification task\n",
        "    shuffle=False  # Do not shuffle test data\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "model.save('model.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}